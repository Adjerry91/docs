"use strict";(self.webpackChunkvrcft_docs=self.webpackChunkvrcft_docs||[]).push([[8212],{7114:a=>{a.exports=JSON.parse('{"pluginId":"default","version":"v4.0","label":"v4.0","banner":"unmaintained","badge":true,"noIndex":false,"className":"docs-version-v4.0","isLast":false,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"\ud83d\udc40 Welcome to VRCFT!","href":"/docs/v4.0/intro","docId":"intro"},{"type":"category","label":"Avatar Setup","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Basics","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Install VRCFaceTracking","href":"/docs/v4.0/tutorial-avatars/tutorial-avatars-basics/install-vrcft","docId":"tutorial-avatars/tutorial-avatars-basics/install-vrcft"}],"href":"/docs/v4.0/category/basics"},{"type":"category","label":"Intermediate","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"Parameters","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Parameters","href":"/docs/v4.0/tutorial-avatars/tutorial-avatars-extras/parameters/","docId":"tutorial-avatars/tutorial-avatars-extras/parameters/parameters"},{"type":"category","label":"Types","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Binary Parameters","href":"/docs/v4.0/tutorial-avatars/tutorial-avatars-extras/parameters/types/binary","docId":"tutorial-avatars/tutorial-avatars-extras/parameters/types/binary"},{"type":"link","label":"Float Parameters","href":"/docs/v4.0/tutorial-avatars/tutorial-avatars-extras/parameters/types/float","docId":"tutorial-avatars/tutorial-avatars-extras/parameters/types/float"}],"href":"/docs/v4.0/category/types"},{"type":"link","label":"Eye Tracking Parameters","href":"/docs/v4.0/tutorial-avatars/tutorial-avatars-extras/parameters/eye-tracking-parameters","docId":"tutorial-avatars/tutorial-avatars-extras/parameters/eye-tracking-parameters"},{"type":"link","label":"Lip Tracking Parameters","href":"/docs/v4.0/tutorial-avatars/tutorial-avatars-extras/parameters/lip-tracking-parameters","docId":"tutorial-avatars/tutorial-avatars-extras/parameters/lip-tracking-parameters"}],"href":"/docs/v4.0/category/parameters"},{"type":"link","label":"Eye Shapes","href":"/docs/v4.0/tutorial-avatars/tutorial-avatars-extras/eye-blendshapes","docId":"tutorial-avatars/tutorial-avatars-extras/eye-blendshapes"},{"type":"link","label":"Lip Shapes","href":"/docs/v4.0/tutorial-avatars/tutorial-avatars-extras/lip-blendshapes","docId":"tutorial-avatars/tutorial-avatars-extras/lip-blendshapes"}],"href":"/docs/v4.0/category/intermediate"}],"href":"/docs/v4.0/category/avatar-setup"},{"type":"category","label":"Tracking Modules","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"SRanipal (VIVE)","href":"/docs/v4.0/tutorial-modules/sranipal","docId":"tutorial-modules/sranipal"}],"href":"/docs/v4.0/category/tracking-modules"},{"type":"category","label":"Hardware","collapsible":true,"collapsed":true,"items":[{"type":"category","label":"VIVE","collapsible":true,"collapsed":true,"items":[{"type":"link","label":"Vive Facial Tracker","href":"/docs/v4.0/hardware/VIVE/face-tracker","docId":"hardware/VIVE/face-tracker"},{"type":"link","label":"Vive Pro Eye","href":"/docs/v4.0/hardware/VIVE/vpe","docId":"hardware/VIVE/vpe"},{"type":"link","label":"Vive Wireless + Eye & Face Tracking","href":"/docs/v4.0/hardware/VIVE/wireless","docId":"hardware/VIVE/wireless"}]},{"type":"link","label":"iPhone ARKit Tracking","href":"/docs/v4.0/hardware/iphone-arkit","docId":"hardware/iphone-arkit"},{"type":"link","label":"Quest Pro","href":"/docs/v4.0/hardware/quest-pro","docId":"hardware/quest-pro"}],"href":"/docs/v4.0/category/hardware"}]},"docs":{"hardware/iphone-arkit":{"id":"hardware/iphone-arkit","title":"iPhone ARKit Tracking","description":"Document still under construction","sidebar":"tutorialSidebar"},"hardware/quest-pro":{"id":"hardware/quest-pro","title":"Quest Pro","description":"The Meta Quest Pro provides eye gaze tracking, detailed eye expression tracking, and face tracking.","sidebar":"tutorialSidebar"},"hardware/VIVE/face-tracker":{"id":"hardware/VIVE/face-tracker","title":"Vive Facial Tracker","description":"Introduction","sidebar":"tutorialSidebar"},"hardware/VIVE/vpe":{"id":"hardware/VIVE/vpe","title":"Vive Pro Eye","description":"Overview","sidebar":"tutorialSidebar"},"hardware/VIVE/wireless":{"id":"hardware/VIVE/wireless","title":"Vive Wireless + Eye & Face Tracking","description":"Vive Wireless with a Vive Pro Eye and Vive Facial Tracker works (with some quirks).","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"\ud83d\udc40 Welcome to VRCFT!","description":"\u2754 Resources","sidebar":"tutorialSidebar"},"tutorial-avatars/tutorial-avatars-basics/install-vrcft":{"id":"tutorial-avatars/tutorial-avatars-basics/install-vrcft","title":"Install VRCFaceTracking","description":"Download the latest release from the GitHub.","sidebar":"tutorialSidebar"},"tutorial-avatars/tutorial-avatars-extras/eye-blendshapes":{"id":"tutorial-avatars/tutorial-avatars-extras/eye-blendshapes","title":"Eye Shapes","description":"Eye tracking blend shapes are for non-eye parts of the face. Eyeball rotations should be weighted on a bone transforms to be animated. SRanipal eye tracking can control 18 blendShapes as follows:","sidebar":"tutorialSidebar"},"tutorial-avatars/tutorial-avatars-extras/lip-blendshapes":{"id":"tutorial-avatars/tutorial-avatars-extras/lip-blendshapes","title":"Lip Shapes","description":"Through SRanipal\u2019s lip-tracking features, an avatar\u2019s blendShape values can be animated with the player\u2019s lip movement. A compatible avatar for SRanipal  38 blendshapes (37 + 1 no detect). Demonstrated in this section.","sidebar":"tutorialSidebar"},"tutorial-avatars/tutorial-avatars-extras/parameters/eye-tracking-parameters":{"id":"tutorial-avatars/tutorial-avatars-extras/parameters/eye-tracking-parameters","title":"Eye Tracking Parameters","description":"|Parameter Name (Case Sensitive)|Description|Eye|","sidebar":"tutorialSidebar"},"tutorial-avatars/tutorial-avatars-extras/parameters/lip-tracking-parameters":{"id":"tutorial-avatars/tutorial-avatars-extras/parameters/lip-tracking-parameters","title":"Lip Tracking Parameters","description":"VRCFaceTracking provides the user with many lip tracking expression parameters.","sidebar":"tutorialSidebar"},"tutorial-avatars/tutorial-avatars-extras/parameters/parameters":{"id":"tutorial-avatars/tutorial-avatars-extras/parameters/parameters","title":"Parameters","description":"VRCFaceTracking controls Expression Parameters on an Avatar to drive facial expressions. All facial tracking expression parameters come in the following forms: Float, Binary, and Bool, with some exceptions for certain parameters.","sidebar":"tutorialSidebar"},"tutorial-avatars/tutorial-avatars-extras/parameters/types/binary":{"id":"tutorial-avatars/tutorial-avatars-extras/parameters/types/binary","title":"Binary Parameters","description":"Nearly all VRCFaceTracking expression parameters can be used as a Binary parameter. Exceptions are listed in the Parameters list above.","sidebar":"tutorialSidebar"},"tutorial-avatars/tutorial-avatars-extras/parameters/types/float":{"id":"tutorial-avatars/tutorial-avatars-extras/parameters/types/float","title":"Float Parameters","description":"Float parameters are, for the most part, the best parameter type to use: they are the most flexible, have priority*, get smoothed over the network (if under priority*), and the easiest to setup parameter. Float parameters have the ability to be used in Blend Trees, which gives them the ability to blend between multiple animations at a time.","sidebar":"tutorialSidebar"},"tutorial-modules/sranipal":{"id":"tutorial-modules/sranipal","title":"SRanipal (VIVE)","description":"Set-up","sidebar":"tutorialSidebar"}}}')}}]);